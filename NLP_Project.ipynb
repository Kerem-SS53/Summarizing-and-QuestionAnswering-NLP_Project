{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNPXpQxjiMnG/r1ak/k8XYF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"soJl7ZYAeoe-"},"outputs":[],"source":["!pip install datasets evaluate transformers[\"sentencepiece\"]\n","!pip install PyPDF2\n","!pip install pandas\n","!pip install python-docx\n","!pip install tabula-py\n","!pip install pip install openpyxl\n","!pip install huggingface_hub\n","!pip install nltk\n","!pip install torch\n","!pip install transformers"]},{"cell_type":"code","source":["import pandas as pd\n","from docx import Document\n","import tabula\n","import json\n","import openpyxl\n","import csv\n","import PyPDF2\n","from transformers import pipeline, AutoTokenizer\n","import nltk\n","nltk.download(\"punkt\")\n","\n","\n","\n","\n","def convert_docx_to_csv(docx_file, csv_file):\n","    doc = Document(docx_file)\n","    text_content = []\n","    for paragraph in doc.paragraphs:\n","        text_content.append(paragraph.text)\n","    ink = pd.DataFrame({'Text': text_content})\n","    ink.to_csv(csv_file, index=False)\n","\n","\n","def convert_pdf_to_csv(pdf_file, csv_file):\n","    pdf_text = \"\"\n","    with open(pdf_file, 'rb') as pdf_file:\n","        pdf_reader = PyPDF2.PdfReader(pdf_file)\n","        num_pages = len(pdf_reader.pages)\n","\n","        for page_num in range(num_pages):\n","            page = pdf_reader.pages[page_num]\n","            pdf_text += page.extract_text()\n","\n","\n","    lines = pdf_text.split('\\n')\n","\n","\n","    with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n","        csv_writer = csv.writer(file)\n","\n","\n","        for line in lines:\n","          csv_writer.writerow([line])\n","\n","\n","\n","def convert_json_to_csv(json_file, csv_file):\n","    with open(json_file, 'r') as json_data:\n","        data = json.load(json_data)\n","    ink = pd.DataFrame(data)\n","    ink.to_csv(csv_file, index=False)\n","\n","\n","def convert_excel_to_csv(excel_file, csv_file):\n","    xls = openpyxl.load_workbook(excel_file)\n","    sheet = xls.active\n","    data = sheet.values\n","    ink = pd.DataFrame(data)\n","    ink.to_csv(csv_file, index=False)\n","\n","\n","def clean_text(text):\n","    cleaned_text = ' '.join(text.split())\n","    return cleaned_text\n","\n","\n","\n","def summarize_text(text, model_checkpoint=\"t5-large\"):\n","    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","    summarization_pipeline = pipeline(\"summarization\", model=model_checkpoint, tokenizer=tokenizer)\n","\n","\n","    chunks = [text[i:i+1000] for i in range(0, len(text), 1000)]\n","\n","    summary_parts = []\n","\n","    for chunk in chunks:\n","        summary = summarization_pipeline(chunk, max_length=100, min_length=0, do_sample=False)\n","        summary_parts.append(summary[0]['summary_text'])\n","\n","\n","    final_summary = ' '.join(summary_parts)\n","\n","    return final_summary\n","\n","input_file = 'document_path'\n","\n","output_csv = 'output_csv'\n","\n","file_extension = input_file.split('.')[-1].lower()\n","\n","if file_extension == 'docx':\n","    convert_docx_to_csv(input_file, output_csv)\n","elif file_extension in ('xlsx', 'xls'):\n","    convert_excel_to_csv(input_file, output_csv)\n","elif file_extension == 'pdf':\n","    convert_pdf_to_csv(input_file, output_csv)\n","elif file_extension == 'json':\n","    convert_json_to_csv(input_file, output_csv)\n","else:\n","    print(f\"Unsupported file format: {file_extension}\")\n","\n","print(f\"The document has been converted and saved as '{output_csv}'.\")\n","\n","\n","\n","\n","with open(output_csv, 'r', encoding='utf-8') as file:\n","    csv_reader = csv.reader(file)\n","    text = \" \".join(row[0] for row in csv_reader)\n","\n","\n","cleaned_text = clean_text(text)\n","\n","final_summary = summarize_text(cleaned_text, model_checkpoint=\"t5-large\")\n","print(\"Summary:\")\n","print(final_summary)\n","\n","\n","\n","import torch\n","from transformers import BertForQuestionAnswering, BertTokenizer, pipeline\n","\n","\n","\n","model_checkpoint =\"bert-large-uncased-whole-word-masking-finetuned-squad\"\n","model = BertForQuestionAnswering.from_pretrained(model_checkpoint)\n","Tokenizer = BertTokenizer.from_pretrained(model_checkpoint)\n","\n","question_answerer = pipeline(\"question-answering\", model=model, tokenizer=Tokenizer)\n","\n","question = input(\" What is your question about the document? \")\n","\n","context= cleaned_text\n","\n","answer = question_answerer(question=question, context= cleaned_text,)\n","\n","\n","\n","print(\"Answer:\" , answer[\"answer\"])\n","\n"],"metadata":{"id":"xNXDBMFDepU_"},"execution_count":null,"outputs":[]}]}